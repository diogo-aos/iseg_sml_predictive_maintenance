{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "236de8bb-42bd-46e5-8f69-f8a23dbea378",
   "metadata": {},
   "source": [
    "# TODOs\n",
    "- [X] send email to Errol - does the team that installed an asset do all other maintenance related events for the same asset? Useful for determining team productivity and effectiveness.\n",
    "- [X] Meaning of previous_repairs and previous_unplanned in assets table.\n",
    "At first it seemed that it was simply the values of the last row from the events table, but it doesn't seem to match up.\n",
    "- [ ] Meaning of non-zero previous_repairs and previous_unplanned in first event after installation.\n",
    "- [ ] Transform datetimes and time periods to numeric data\n",
    "- [ ] Augment assets data with events statistics: number of replacements, number of repairs, average time between events, ...?\n",
    "\n",
    "\n",
    "Source:\n",
    "- [predictive maintenance article - towardsdatascience](https://towardsdatascience.com/how-to-implement-machine-learning-for-predictive-maintenance-4633cdbe4860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e0086f-4fd4-4044-b7bf-72ebd1b0e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library\n",
    "from typing import List\n",
    "\n",
    "# data and viz\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# numeric\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706a64c3-38b1-4e47-ac79-99da772c2a0e",
   "metadata": {},
   "source": [
    "# 1. Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fee7bb2-65ac-470f-b2b5-3e9b2e2389f1",
   "metadata": {},
   "source": [
    "## 1.1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bbde42-74bb-40de-b6c9-321a63a37b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles = !ls data/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328272fc-1153-4da5-8540-24151485d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for fn in datafiles:\n",
    "    dataset_name = fn.split('/')[-1].rstrip('.csv')\n",
    "    datasets[dataset_name] = pd.read_csv(fn)\n",
    "\n",
    "for name, dataset in datasets.items():\n",
    "    print('\\n'*3, name, '\\n')\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee72b434-d06f-4063-a922-ae7a48ce27ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "(datasets['replacement_data'].shape[0] + datasets['repair_data'].shape[0]) == datasets['planned_data'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91ae5e3-7e0c-4343-81b5-c623bc3ae82c",
   "metadata": {},
   "source": [
    "The planned data seems to contain all the repair and replacement events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39271781-3ffd-4e74-a57a-07810e55708d",
   "metadata": {},
   "source": [
    "## 1.2. Join all datasets in 2 tables (events, assets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da4651d-6eb6-4c97-b2f1-7c7dbb601c0a",
   "metadata": {},
   "source": [
    "We seem to have 2 types of data. We'll start the process of combining all tables into 2 tables for each of these types:\n",
    "- time series data for maintenance events (\"events\");\n",
    "- and assets' attributes data (\"assets\").\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e485b77-8779-4b03-92d8-840c02c436c7",
   "metadata": {},
   "source": [
    "### 1.2.1. Join events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33587591-2343-4cb5-b262-9355b434ff4a",
   "metadata": {},
   "source": [
    "To combine these tables, we will:\n",
    "1. We'll need to first add a column to repair_data and replacement_data to indicate the type of event.\n",
    "2. All columns are the same, so we can concatenate repair and replacement events.\n",
    "3. Inner join events with planned data. We just need the planned column.\n",
    "\n",
    "Let's call this new dataset \"events\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a790ddb0-ef7c-4883-952b-0ddf66ea6887",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['replacement_data']['type'] = 'replacement'\n",
    "datasets['repair_data']['type'] = 'repair'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be09a18e-8bba-4dba-8189-a416964f6ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['all_events_data'] = pd.concat([datasets['replacement_data'], datasets['repair_data']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a830ce7-0d3c-4105-b2bf-3bbaaa8ec5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.merge(datasets['all_events_data'], datasets['planned_data'], how='inner', on=['event_id', 'asset_id', 'event_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bce5ef1-38e2-49e0-a8f3-ebf0d5d998ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = ['event_date', 'installed_date']\n",
    "for col in date_cols:\n",
    "    events[col] = pd.to_datetime(events[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3082aa4a-bf9a-416d-941d-6e0ac60e8d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "events.sort_values(by=['asset_id', 'event_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd26a75-740c-4801-b2ee-e8999c448754",
   "metadata": {},
   "source": [
    "### 1.2.2 Join assets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34037067-e86b-4a46-b22c-7ee71e2367f9",
   "metadata": {},
   "source": [
    "Let's join the attributes of the assets in a single table:\n",
    "- asset_attribute_data_general\n",
    "- asset_attribute_data_usage\n",
    "- asset_attribute_data_weather\n",
    "- asset_data\n",
    "\n",
    "Let's call this new dataset \"assets\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c7585-4f59-42de-a02d-710b2a027f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = pd.merge(datasets['asset_attribute_data_general'], datasets['asset_attribute_data_usage'], on='asset_id')\n",
    "assets = pd.merge(assets, datasets['asset_attribute_data_weather'], on='asset_id')\n",
    "assets = pd.merge(assets, datasets['asset_data'], on='asset_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fcfaf8-7455-4e57-81cc-0395fd4ef3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = ['end_date', 'start_date']\n",
    "for col in date_cols:\n",
    "    assets[col] = pd.to_datetime(assets[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5bc660-6710-4e64-a170-5c3a1205e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets['total_useful_life'] = assets['end_date'] - assets['start_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cfbf4d-98c7-4ae2-b491-0b1f5082e253",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93044aed-44b2-45a0-b2b6-8dcdd18796b2",
   "metadata": {},
   "source": [
    "## 1.3. Check for gaps in datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143e8a1b-f6a9-4a0b-af6b-d7e3fd76f0eb",
   "metadata": {},
   "source": [
    "Now we have only 2 tables to work with. One refers to data about maintenance events, the other about asset attributes.\n",
    "\n",
    "Let's check if there are gaps in the data:\n",
    "- Do all assets have maintenance events? If not, why?\n",
    "- Are there events refering to missing assets? These might need to be discarded depending on the following analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc23118-47fd-4a72-994f-0f700975e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do all assets have maintenance events?\n",
    "assets_that_broke = events['asset_id'].unique()\n",
    "print(f'{len(assets_that_broke)}\\t assets that have replacement or repair events')\n",
    "\n",
    "print(f'{assets.shape[0]}\\t assets')\n",
    "\n",
    "assets_without_events = assets[assets['asset_id'].isin(assets_that_broke) == False]\n",
    "print(f'{assets_without_events.shape[0]}\\t assets without events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe0ccc3-6ebf-43dd-88b3-9681a3e4865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_without_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ffae2a-e33e-46eb-bf7c-4a8102abf344",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3bec1b-4c88-44b8-a024-6539a06df30c",
   "metadata": {},
   "source": [
    "Of the 200 registered assets, we have maintenance events on 194.\n",
    "Looking at the data from the 6 that didn't have incidents, no pattern is identified about their attributes.\n",
    "Different teams installed them, they have different materials, locations, weather and were operational on different years.\n",
    "The only similarity is that all these assets have a total useful life well below the 25% percentile.\n",
    "However, there are assets that had a shorter useful life and still had maintenance events.\n",
    "\n",
    "Let's check the statistics for time between events to decide whether to consider that these 6 assets are outliers and exclude them from further exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ec6367-cb69-494e-a1d6-e333620d8aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "events['time_since_last_event'] = events['event_date'] - events['installed_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ce67b5-b95c-45ba-bb5b-b9e10cc1a64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "events['time_since_last_event'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b03aab-2d4d-4705-8e2d-9eaea7289dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 0.9\n",
    "print(events['time_since_last_event'].quantile(q))\n",
    "print(f'# events over quantile {q}: {2032*(1-q)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41424a78-cd84-466e-9c8d-ee826068c2c0",
   "metadata": {},
   "source": [
    "For 10% of events (~203 events), the time elapsed since the previous event was higher than 321 days.\n",
    "Of the 6 assets than didn't have events, 5 have a useful life below 300 days.\n",
    "This means that it's plausible that these 6 assets didn't have any maintenance events, given their brief useful life, and we'll reject the hypothesis that it's due to missing data in the events table\n",
    "\n",
    "\n",
    "They will not be removed from the analysis when considering only assets' attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b37c74-1185-4a5d-b97c-b58545681331",
   "metadata": {},
   "source": [
    "## 1.4. Data Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a1a23b-30fc-455f-8d86-5ac65fb56b03",
   "metadata": {},
   "source": [
    "The events and assets tables are two different kinds of data and we can use them to answer lots of questions.\n",
    "1. Which asset attributes are correlated with number of maintenance events?\n",
    "2. Which attributes are correlated with total useful life?\n",
    "3. Are there better performing teams?\n",
    "4. Should we be avoiding certain materials in specific locations or weather clusters?\n",
    "5. Can we predict the remaining useful life of an asset within several given time horizons (e.g. 30, 90, 180 days)?\n",
    "\n",
    "In section 2., we'll use the events data to augment the assets table and gather as much insights as possible about questions 1-4, and others that might arise during analysis.\n",
    "\n",
    "These insights will be used to guide question 5, in section 3.\n",
    "There, we'll build and describe a functional pipeline to predict approximate remaining useful life for each asset.\n",
    "**This pipeline can then be used in production, informing management decisions and guiding operation and maintenance teams in the field for reducing costs and downtime, and increase team productivity and customer satisfaction.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bff7d4-8c8d-4f56-a0e8-ba054b1d3896",
   "metadata": {},
   "source": [
    "# 2. Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ece22ed-d91b-466e-8dbf-0204259aad6f",
   "metadata": {},
   "source": [
    "## 2.1. Transforming features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d943b133-db88-4d2d-88b0-391c4b6084c6",
   "metadata": {},
   "source": [
    "### 2.1.1. Transforming categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e8367b-32ab-40e0-91ad-c7a9f16db145",
   "metadata": {},
   "source": [
    "For computing the correlation of the different features, we have to transform some of them.\n",
    "Specifically, we'll need to transform categorical features (team, line, material).\n",
    "\n",
    "Let's make a copy of the original assets table and apply this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae2094d-1ed6-4f6e-849d-10c3aed26bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets2 = assets.copy()\n",
    "events2 = events.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d431a32-5e0f-451a-bbea-bd5ae542241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets2 = pd.get_dummies(assets2, columns=['asset_material', 'asset_line', 'asset_weather_cluster', 'asset_install_team', 'asset_weather_cluster'])\n",
    "events2 = pd.get_dummies(events2, columns=['type', 'planned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537f259b-0ac0-4fad-8701-cc0074264c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beba1fb-f6e2-4227-99d1-f4d07729bd7c",
   "metadata": {},
   "source": [
    "### 2.1.2. Describing `previous_repairs` and `previous_unplanned`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0648311-8920-48a3-8843-c720dae4b2a0",
   "metadata": {},
   "source": [
    "The `previous_repairs` and `previous_unplanned` columns are present both in the events and assets tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3914c5e4-19a2-4599-ba11-3f2bf613cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "events[events['asset_id'] == 'A:xoauw0'] .sort_values('event_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ede49e-525e-4b46-a143-d2a903ce62f8",
   "metadata": {},
   "source": [
    "`events`\n",
    "\n",
    "After studying the events sequence for several assets, the following was concluded.\n",
    "- In the events table, the previous_repairs column contains how many repair events ocurred since the last replacement event.\n",
    "- The previous_unplanned contains how many unplanned repair events occurred snce the last replacement event.\n",
    "- Each time a replacement happens, both counters are reset to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e6c93-28e3-4322-ac90-116244473535",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets[assets['previous_unplanned'] > 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06172c0-493f-4914-a76a-dda1f451e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_id = 'A:z7x72w'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18de6f28-a099-4e80-bf35-38c3330298c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets[assets['asset_id'] == asset_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95859486-3b87-473a-a8b7-7871091ca42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "events[events['asset_id'] == asset_id] .sort_values('event_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eda2c49-27a3-4540-a010-d57ea7160f06",
   "metadata": {},
   "source": [
    "`assets`\n",
    "After studying the events sequence for several assets and their corresponding assets row, the following was concluded:\n",
    "- The previous_repairs and previous_unplanned features of the assets table represen the total number repairs and number of unplanned repairs since the last replacement, at the moment of installation.\n",
    "- This can be observed, for example, in the data regarding the asset with ID \"A:z7x72w\".\n",
    "  - previous_repairs is 0 and previous_unplanned is 6 in the assets table. The first event is an unplanned repair. Both counters are incremented in the events table.\n",
    "- It should be noted that in the events table, previous_unplanned is always lower than previous_repairs, but in the assets table such is not the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dcdf39-6af7-4f4f-9d12-063c733fcc5d",
   "metadata": {},
   "source": [
    "### 2.1.3 Transforming dates and time periods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b2bd2e-ceb0-48b9-9f6c-f44092e3af19",
   "metadata": {},
   "source": [
    "We'll also need to transform features containing dates and time durations, because datetimes and timedeltas can't be directly correlated with other numeric data.\n",
    "\n",
    "- We'll make a feature from the year to try to understand if older installations are less reliable.\n",
    "- We'll use the month and day to make a sinusoidal wave with a period of one year and no phase shift, to understand if the seasons and time of the year also has an influence.*\n",
    "  - We use a sinusoid so that the last days from one year are similar to the first days from the following year.\n",
    "- We'll also add a weekday categorical variable (one hot encoded) to see understand if more \n",
    "\n",
    "\\* [method for convertion](https://math.stackexchange.com/a/650235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddcd56f-5d2c-49ed-bff8-4b41af25b80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_of_year_to_sin(day: pd.Timestamp,\n",
    "                       period: float = 365.0,\n",
    "                       phase_shift: float = 84.0):\n",
    "    '''\n",
    "    day: a pandas timestamp\n",
    "    period: specifies the period of the wave\n",
    "    phase_shift: shifts the sine wave so the the peaks are at specific days, 84 makes the peak ~match the solstice\n",
    "    '''\n",
    "    return math.sin((2 * math.pi) / period * (day.day_of_year - phase_shift))\n",
    "    \n",
    "\n",
    "weekdays = {0: 'monday',\n",
    "            1: 'tuesday',\n",
    "            2: 'wednesday',\n",
    "            3: 'thursday',\n",
    "            4: 'friday',\n",
    "            5: 'saturday',\n",
    "            6: 'sunday'\n",
    "           }\n",
    "\n",
    "def augment_datetime(df: pd.DataFrame, columns: List[str]):\n",
    "    '''\n",
    "    for each pandas.Timestamp column in dataframe df, create 3 features:\n",
    "    - year (integer)\n",
    "    - sine wave (from day and month) with yearly period\n",
    "    - weekday, one hot encoded\n",
    "    for each pandas.Timedelta column, convert to integer in days\n",
    "    '''\n",
    "    for col in columns:\n",
    "        if col not in df:\n",
    "            raise Exception(f'column {col} not present in dataframe')\n",
    "            \n",
    "        if isinstance(df[col].iloc[0], pd.Timestamp):\n",
    "            print(col)\n",
    "            df[col + '_year'] = df[col].map(lambda d: d.year)\n",
    "            df[col + '_weekday'] = df[col].map(lambda d: weekdays[d.day_of_week])\n",
    "            df[col + '_sin_year'] = df[col].map(day_of_year_to_sin)\n",
    "            \n",
    "            df = pd.get_dummies(df, columns=[col + '_weekday'])\n",
    "            \n",
    "        elif isinstance(df[col].iloc[0], pd.Timedelta):\n",
    "            df[col + '_days_int'] = df[col].map(lambda td: td.days)\n",
    "            \n",
    "        else:\n",
    "            raise TypeError(f'{col} is not of type pandas.Timestamp or pandas.Timedelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc3eef2-3524-40c4-a023-0a05905d9cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_datetime(assets2, ['end_date', 'start_date'])\n",
    "augment_datetime(events2, ['event_date', 'installed_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808a7dbb-37ea-4f70-999a-1effdfb65ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "events2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0144bb-3a98-4a29-8f98-946f90b8cb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets2['total_useful_life'] = assets2['total_useful_life'].map(lambda dt: dt.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e330c24-bf97-4fb2-b9a2-52af894370f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets2.corr()['total_useful_life'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3cbf09-d94c-4d8b-ada0-f82541372a09",
   "metadata": {},
   "source": [
    "# 3. Predictive maintenance models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61072096-fed8-4e8e-9975-7162adc72848",
   "metadata": {},
   "source": [
    "- Augment events dataset with data from assets table.\n",
    "- Augment events dataset to have columns for indicating whether another event will happen in different time horizons: 30, 90, 180, 360 days.\n",
    "- We can have different models, one for each time horizon and they'll be binary class models.\n",
    "- Or, we can have a multi class model, where each time horizon is a different class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
